{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "#GundGallery_Alpha.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWjzl82Nv7IG"
      },
      "source": [
        "# #GundGallery\n",
        "\n",
        "Wellcome to our Alpha version of our #GundGallery art developer and interpreter tool.\n",
        "\n",
        "This program uses Machine Learning Neural Network to interpret an art piece to text, create an art piece from text, or create a new art piece from your chosen art piece with your highlighted element of the piece.\n",
        "This program also includes a mutation algorithm that continuously merge and augment artworks and texts over multiple cycles (generations) to create thousands of artworks or text interpretations, all of which is filtered for the ones that best matches your target/chosen topic or artwork.\n",
        "\n",
        "For faster results we encourage you to secure stable internet connections and a Google Colab Pro account. But a Google Colab Pro account is totally not necessary.\n",
        "\n",
        "**Disclaimer:** Machine Learning Neural Network is a highly complicated mathematical simulator that is equivalent to a black box. If you have any suggestions or find interesting patterns in the function of this program, please let our development team know at:\n",
        "pham2@kenyon.edu (Minh Pham '23), beshentseva2@kenyon.edu ( Irina Beshentseva '24), tjandra1@kenyon.edu (Isaac Tjandra '24), or niehoff1@kenyon.edu (Mart Niehoff '23)\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1) Click the play button titled \"System Set-up\" and follow isntructions to start the system - About 5 minutes.\n",
        "\n",
        "2) Select your setting options in the \"Art Interpreter & Developer\" form:\n",
        "- genre: choose the genre of art you want to work in.\n",
        "\n",
        "- save_each: ask the program to display to you intermediate results after n number of cycles/generations. This will slightly slow down your program if you set it too frequently\n",
        "\n",
        "- generations: choose the total number of cycles/generations you want the program to run for. This will significantly slow down your program if you choose a number too high.\n",
        "\n",
        "\n",
        "3) Confirm your settings and press the start button next to the title \"Art Interpreter & Developer\".\n",
        "\n",
        "4) Follow the program instructions.\n",
        "\n",
        "5) Download your final image if you would like. Images will be downloaded in .jpeg format and text will be downloaded in .txt format.\n",
        "\n",
        "##Notes\n",
        "\n",
        "1) If you forget to download your previous results, they are still stored in the \"result\" file in the \"Files\" tab of your left tool collumn.\n",
        "\n",
        "2) We do not recommend unauthorized changes to the code. All chagnes that you made in this code will not be saved.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Wgv0HIv3Uk",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15287e2-798c-423d-83c7-e780095d5f85"
      },
      "source": [
        "#@title <-------System Set-up: Click the Button \n",
        "import os, sys\n",
        "\n",
        "class HiddenPrints:\n",
        "    def __enter__(self):\n",
        "        self._original_stdout = sys.stdout\n",
        "        sys.stdout = open(os.devnull, 'w')\n",
        "\n",
        "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
        "        sys.stdout.close()\n",
        "        sys.stdout = self._original_stdout\n",
        "        \n",
        "        \n",
        "with HiddenPrints():\n",
        "    import subprocess\n",
        "    import re\n",
        "\n",
        "    nvcc = subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"utf-8\")\n",
        "    version = re.findall(\"release (\\d+\\.\\d+)\", nvcc)[0]\n",
        "\n",
        "    pytorch_suffix = {\n",
        "        \"10.0\": \"+cu100\",\n",
        "        \"10.1\": \"+cu101\",\n",
        "        \"10.2\": \"\",\n",
        "    }\n",
        "\n",
        "    pytorch_version = \"1.7.1\" + (pytorch_suffix[version] if version in pytorch_suffix else \"+cu110\")\n",
        "    torchvision_version = \"0.8.2\" + (pytorch_suffix[version] if version in pytorch_suffix else \"+cu110\")\n",
        "\n",
        "    %cd /content\n",
        "    !mkdir result\n",
        "    !git clone https://github.com/isaacwanderers/artcreate.git\n",
        "    %cd artcreate\n",
        "\n",
        "    try:\n",
        "      import torch\n",
        "    except:\n",
        "      !pip install torch=={pytorch_version} -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "    try:\n",
        "      import ipyplot\n",
        "    except:\n",
        "      !pip install ipyplot\n",
        "\n",
        "    try:\n",
        "      import torchvision\n",
        "    except:\n",
        "      !pip install torchvision=={torchvision_version} -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "    try:\n",
        "      import wget\n",
        "    except:\n",
        "      !pip install wget\n",
        "\n",
        "    import urllib3\n",
        "restart = 0\n",
        "if urllib3.__version__ != \"1.25.11\":\n",
        "    restart = 1\n",
        "    print(\"BIGAN Neural Network requires urllib3 version 1.25.11.\\nThe system will replace the current version of urllib3 with urllib3 1.25.11 and restart runtime.\\nThis will no affect your future Colab work space, only this one program's environment.\\nPlease re-initialize system set-up after restart!\")\n",
        "    \n",
        "if restart ==1:\n",
        "    with HiddenPrints():\n",
        "        !pip install pytorch_pretrained_biggan==0.1.1 pymoo==0.4.2.1 kornia==0.4.1 ftfy==5.8 tensorboard==2.4.1\n",
        "        import os\n",
        "        os.kill(os.getpid(), 9)\n",
        "\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "import glob\n",
        "import random\n",
        "import array\n",
        "import PIL.Image\n",
        "import ipyplot\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "from os.path import exists\n",
        "from pymoo.optimize import minimize\n",
        "from pymoo.algorithms.so_genetic_algorithm import GA\n",
        "from pymoo.factory import get_algorithm, get_decision_making, get_decomposition\n",
        "from pymoo.visualization.scatter import Scatter\n",
        "from IPython.display import Image, display\n",
        "import torchvision\n",
        "import urllib.request\n",
        "import wget\n",
        "\n",
        "from config import get_config\n",
        "from problem import GenerationProblem\n",
        "from operators import get_operators\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "def display_genre_images(genre):\n",
        "  image_files = sorted(glob.glob(\"/content/artcreate/gpt2_images/\" + genre +\"/*.jpg\")) \n",
        "  all_images = []\n",
        "  all_file_names = []\n",
        "\n",
        "  for f in image_files:\n",
        "    #enumerate() returns the index number/order number of the images and the root pathway of the image.\n",
        "    try:\n",
        "      image = PIL.Image.open(f)\n",
        "      #open each image as an Image object class, which was imported above from the PIL module.\n",
        "      all_images.append(image)\n",
        "      all_file_names.append(f)\n",
        "    except:\n",
        "      print(\"error reading\", f)\n",
        "\n",
        "  file_name = [i.rpartition('/')[2] for i in all_file_names]\n",
        "  ipyplot.plot_images(all_images, file_name, img_width=150)\n",
        "  if len(file_name) <= 20:\n",
        "    time.sleep(15)\n",
        "  else:\n",
        "    time.sleep(30)\n",
        "  return file_name\n",
        "\n",
        "import IPython\n",
        "import uuid\n",
        "from google.colab import output\n",
        "from google.colab import files\n",
        "\n",
        "class InvokeButton(object):\n",
        "  def __init__(self, title, callback):\n",
        "    self._title = title\n",
        "    self._callback = callback\n",
        "\n",
        "  def _repr_html_(self):\n",
        "    callback_id = 'button-' + str(uuid.uuid4())\n",
        "    output.register_callback(callback_id, self._callback)\n",
        "\n",
        "    template = \"\"\"<button id=\"{callback_id}\">{title}</button>\n",
        "        <script>\n",
        "          document.querySelector(\"#{callback_id}\").onclick = (e) => {{\n",
        "            google.colab.kernel.invokeFunction('{callback_id}', [], {{}})\n",
        "            e.preventDefault();\n",
        "          }};\n",
        "        </script>\"\"\"\n",
        "    html = template.format(title=self._title, callback_id=callback_id)\n",
        "    return html\n",
        "\n",
        "def download_file():\n",
        "  files.download(result_path)\n",
        "  print(\"File Successfully Downloaded!\")\n",
        "\n",
        "def save_callback(algorithm):\n",
        "  global iteration\n",
        "  global config\n",
        "\n",
        "  iteration += 1\n",
        "  if iteration % config.save_each == 0 or iteration == config.generations:\n",
        "      if config.problem_args[\"n_obj\"] == 1:\n",
        "          sortedpop = sorted(algorithm.pop, key=lambda p: p.F)\n",
        "          X = np.stack([p.X for p in sortedpop])  \n",
        "      else:\n",
        "          X = algorithm.pop.get(\"X\")\n",
        "      \n",
        "      ls = config.latent(config)\n",
        "      ls.set_from_population(X)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          generated = algorithm.problem.generator.generate(ls, minibatch=config.batch_size)\n",
        "          name = \"genetic-it-%d.jpg\" % (iteration) if iteration < config.generations else \"genetic-it-final.jpg\"\n",
        "\n",
        "          if config.task == \"txt2img\":\n",
        "              algorithm.problem.generator.save(generated, os.path.join(config.tmp_folder, name))\n",
        "              display(Image(os.path.join(config.tmp_folder, name)))\n",
        "          elif config.task == \"img2txt\":\n",
        "              print(\"\\n\".join(generated))\n",
        "\n",
        "print(\"The system has finished setting up!\\nYou are good to start using the development modes.\\nCaution: Remember to rerun the set up by clicking the button above whenever this line disappears.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The system has finished setting up!\n",
            "You are good to start using the development modes.\n",
            "Caution: Remember to rerun the set up by clicking the button above whenever this line disappears.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvZFRZtcv8Mp",
        "cellView": "form"
      },
      "source": [
        "#@title <-------Art Interpreter & Developer\n",
        "#@markdown Choose your settings below and start the program.\n",
        "\n",
        "#@markdown The program may ask for your input below as it executes.\n",
        "\n",
        "#@markdown Each development mode takes 15 - 30 minutes to complete. The program will slow down if you run it more than 10 times at once.\n",
        "\n",
        "#@markdown If the program slows down, closing out of the browser and reopen the program may help.\n",
        "development_mode = \"interpret Gund Gallery art to text\" #@param [\"interpret Gund Gallery art to text\", \"create art from text\", \"create new art from Gund Gallery art\"]\n",
        "genre = \"Mixed Media Art\" #@param [\"Drawing\", \"Mixed Media Art\", \"Painting\", \"Photograph\", \"Print\", \"Sculpture\"]\n",
        "save_each =  \"200\"#@param [\"100\", \"200\", \"300\", \"400\", \"500\", \"600\", \"700\", \"800\", \"900\", \"1000\"]\n",
        "generations =  \"400\"#@param [\"100\", \"200\", \"300\", \"400\", \"500\", \"600\", \"700\", \"800\", \"900\", \"1000\"]\n",
        "save_each = int(save_each)\n",
        "generations = int(generations)\n",
        "if development_mode == \"interpret Gund Gallery art to text\":\n",
        "  file_exists = exists('/content/artcreate/gpt2/weights/gpt2-pytorch_model.bin')\n",
        "  if not file_exists:\n",
        "    print('Setting up image recognition system for the first time')\n",
        "    ! chmod 755 ./download-weights.sh\n",
        "    ! ./download-weights.sh GPT2\n",
        "    print('Finish setting up image recognitiion system!')\n",
        "  print(\"---All images available in genre---\")\n",
        "  file_name = display_genre_images(genre)\n",
        "  target_image = input(\"Input the file name of the image you want to interpret: \")\n",
        "  while target_image.rpartition('.')[2] != \"jpg\":\n",
        "    print(\"File input error: Please include the file extension!\")\n",
        "    target_image = input(\"Re-input the file name of the image you want to interpret: \")\n",
        "  while target_image not in file_name:\n",
        "    print(\"File input error: Please type your file name correctly!\")\n",
        "    target_image = input(\"Re-input the file name of the image you want to interpret: \")\n",
        "  target = \"/content/artcreate/gpt2_images/\" + genre + \"/\" + target_image\n",
        "  print(\"---Chosen Image---\")\n",
        "  display(Image(target))\n",
        "  print(target_image)\n",
        "  config = \"GPT2\" \n",
        "  generations = generations*3\n",
        "  print(\"---Interpreting your image---\")\n",
        "elif development_mode == \"create art from text\":\n",
        "  target = input(\"Input your target phrase: \") \n",
        "  config = \"DeepMindBigGAN512\"\n",
        "  target = genre.lower() + \" with \" + target\n",
        "  print(\"---Generating your image---\")\n",
        "else:\n",
        "  file_exists = exists('/content/artcreate/gpt2/weights/gpt2-pytorch_model.bin')\n",
        "  if not file_exists:\n",
        "    print('Setting up image recognition system for the first time')\n",
        "    ! chmod 755 ./download-weights.sh\n",
        "    ! ./download-weights.sh GPT2\n",
        "    print('Finish setting up image recognitiion system!')\n",
        "  file_name = display_genre_images(genre)\n",
        "  target_image = input(\"Input the file name of the image you want to develop: \")\n",
        "  while target_image.rpartition('.')[2] != \"jpg\":\n",
        "    print(\"File input error: Please include the file extension!\")\n",
        "    target_image = input(\"Re-input the file name of the image you want to develop: \")\n",
        "  while target_image not in file_name:\n",
        "    print(\"File input error: Please type your file name correctly!\")\n",
        "    target_image = input(\"Re-input the file name of the image you want to develop: \")\n",
        "  target = \"/content/artcreate/gpt2_images/\" + genre + \"/\" + target_image\n",
        "  print(\"---Chosen Image---\")\n",
        "  display(Image(target))\n",
        "  print(target_image)\n",
        "  element = input(\"What element stands out the most to you? (1-2 words) \")  \n",
        "  config = \"GPT2\"\n",
        "   \n",
        "  print(\"---Interpreting your image---\")\n",
        "  config = argparse.Namespace(\n",
        "      config=config,\n",
        "      target=target,\n",
        "      device=\"cuda\",\n",
        "      generations=generations*3,\n",
        "      save_each=save_each,\n",
        "      tmp_folder=\"./tmp\"\n",
        "  )\n",
        "\n",
        "  vars(config).update(get_config(config.config))\n",
        "\n",
        "\n",
        "  iteration = 0          \n",
        "\n",
        "  problem = GenerationProblem(config)\n",
        "  operators = get_operators(config)\n",
        "\n",
        "  if not os.path.exists(config.tmp_folder): os.mkdir(config.tmp_folder)\n",
        "\n",
        "  algorithm = get_algorithm(\n",
        "      config.algorithm,\n",
        "      pop_size=config.pop_size,\n",
        "      sampling=operators[\"sampling\"],\n",
        "      crossover=operators[\"crossover\"],\n",
        "      mutation=operators[\"mutation\"],\n",
        "      eliminate_duplicates=True,\n",
        "      callback=save_callback,\n",
        "      **(config.algorithm_args[config.algorithm] if \"algorithm_args\" in config and config.algorithm in config.algorithm_args else dict())\n",
        "  )\n",
        "\n",
        "  res = minimize(\n",
        "      problem,\n",
        "      algorithm,\n",
        "      (\"n_gen\", config.generations),\n",
        "      save_history=False,\n",
        "      verbose=True,\n",
        "  )\n",
        "\n",
        "\n",
        "  pickle.dump(dict(\n",
        "      X = res.X,\n",
        "      F = res.F,\n",
        "      G = res.G,\n",
        "      CV = res.CV,\n",
        "  ), open(os.path.join(config.tmp_folder, \"genetic_result\"), \"wb\"))\n",
        "\n",
        "\n",
        "  if config.problem_args[\"n_obj\"] == 1:\n",
        "      X = np.atleast_2d(res.X)\n",
        "  else:\n",
        "      try:\n",
        "          result = get_decision_making(\"pseudo-weights\", [0, 1]).do(res.F)\n",
        "      except:\n",
        "          print(\"Warning: cant use pseudo-weights\")\n",
        "          result = get_decomposition(\"asf\").do(res.F, [0, 1]).argmin()\n",
        "      X = res.X[result]\n",
        "      X = np.atleast_2d(X)\n",
        "\n",
        "\n",
        "  ls = config.latent(config)\n",
        "  ls.set_from_population(X)\n",
        "\n",
        "  with torch.no_grad():\n",
        "      generated = problem.generator.generate(ls)\n",
        "\n",
        "  problem.generator.save(generated, (\"/content/result/output.txt\"))\n",
        "  print(\"---Finished interpreting your image---\")\n",
        "  text_file = open(\"/content/result/output.txt\", \"r\")\n",
        "  interpret = text_file.read()\n",
        "  text_file.close()\n",
        "  config = \"DeepMindBigGAN512\"\n",
        "  target = genre.lower() + \" of \" + interpret.rpartition(\"of\")[2] + element*3\n",
        "  !rm /content/result/output.txt\n",
        "  #End of the first text to image intepretation phase of the 3rd development mode.\n",
        "  print(\"---Generating your image---\")\n",
        "\n",
        "config = argparse.Namespace(\n",
        "    config=config,\n",
        "    target=target,\n",
        "    device=\"cuda\",\n",
        "    generations=generations,\n",
        "    save_each=save_each,\n",
        "    tmp_folder=\"./tmp\"\n",
        ")\n",
        "\n",
        "vars(config).update(get_config(config.config))\n",
        "\n",
        "iteration = 0     \n",
        "\n",
        "problem = GenerationProblem(config)\n",
        "operators = get_operators(config)\n",
        "\n",
        "if not os.path.exists(config.tmp_folder): os.mkdir(config.tmp_folder)\n",
        "\n",
        "algorithm = get_algorithm(\n",
        "    config.algorithm,\n",
        "    pop_size=config.pop_size,\n",
        "    sampling=operators[\"sampling\"],\n",
        "    crossover=operators[\"crossover\"],\n",
        "    mutation=operators[\"mutation\"],\n",
        "    eliminate_duplicates=True,\n",
        "    callback=save_callback,\n",
        "    **(config.algorithm_args[config.algorithm] if \"algorithm_args\" in config and config.algorithm in config.algorithm_args else dict())\n",
        ")\n",
        "\n",
        "res = minimize(\n",
        "    problem,\n",
        "    algorithm,\n",
        "    (\"n_gen\", int(config.generations)),\n",
        "    save_history=False,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "\n",
        "pickle.dump(dict(\n",
        "    X = res.X,\n",
        "    F = res.F,\n",
        "    G = res.G,\n",
        "    CV = res.CV,\n",
        "), open(os.path.join(config.tmp_folder, \"genetic_result\"), \"wb\"))\n",
        "\n",
        "\n",
        "if config.problem_args[\"n_obj\"] == 1:\n",
        "    X = np.atleast_2d(res.X)\n",
        "else:\n",
        "    try:\n",
        "        result = get_decision_making(\"pseudo-weights\", [0, 1]).do(res.F)\n",
        "    except:\n",
        "        print(\"Warning: cant use pseudo-weights\")\n",
        "        result = get_decomposition(\"asf\").do(res.F, [0, 1]).argmin()\n",
        "    X = res.X[result]\n",
        "    X = np.atleast_2d(X)\n",
        "\n",
        "ls = config.latent(config)\n",
        "ls.set_from_population(X)\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated = problem.generator.generate(ls)\n",
        "\n",
        "#Check to see if there are previous output files exist in the result directory.\n",
        "#Previous outputs means that this is not the first instance of the program in this script.\n",
        "\n",
        "output_names = sorted(glob.glob(\"/content/result/*\"))\n",
        "if len(output_names) ==0:\n",
        "    n = 1\n",
        "else:\n",
        "    n = int(output_names[-1].rpartition('.')[0].rpartition('_')[2]) + 1\n",
        "\n",
        "if config.task == \"txt2img\":\n",
        "    print(\"---Finished generating your image!---\")\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"RESULT\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    result_path = \"/content/result/output_\" + str(n)+ \".jpg\"\n",
        "    problem.generator.save(generated, result_path)\n",
        "    display(Image(result_path))\n",
        "\n",
        "elif config.task == \"img2txt\":\n",
        "    print(\"---Finished interpreting your image!---\")\n",
        "\n",
        "    print(\"=\"*50)\n",
        "    print(\"RESULT\")\n",
        "    print(\"=\"*50)\n",
        "\n",
        "    result_path = \"/content/result/output_\" + str(n)+ \".txt\"\n",
        "    print(generated)\n",
        "    problem.generator.save(generated, result_path)\n",
        "\n",
        "#This line is here because it cannot be put inside a loop\n",
        "InvokeButton('Download Final Result', download_file) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}