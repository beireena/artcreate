{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CLIP-GLaSS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isaacwanderers/artcreate/blob/main/CLIP_GLaSS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWjzl82Nv7IG"
      },
      "source": [
        "# CLIP-GLaSS\n",
        "\n",
        "Wellcome to the Google's Colab demo of CLIP-GLaSS.\n",
        "\n",
        "For faster results we encourage you to use your own GPU.\n",
        "\n",
        "\n",
        "## Instructions\n",
        "\n",
        "1) Click the play button of the first block titled \"CLIP-GLaSS initialization\" and wait for it to finish the initialization\n",
        "\n",
        "2) Select a config and a target from the form titled \"CLIP-GLaSS settings\"\n",
        "\n",
        "3) Click the play button of the block titled \"CLIP-GLaSS settings\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_Wgv0HIv3Uk",
        "cellView": "form"
      },
      "source": [
        "#@title CLIP-GLaSS initialization\n",
        "import subprocess\n",
        "import re\n",
        "\n",
        "nvcc = subprocess.check_output([\"nvcc\", \"--version\"]).decode(\"utf-8\")\n",
        "version = re.findall(\"release (\\d+\\.\\d+)\", nvcc)[0]\n",
        "\n",
        "pytorch_suffix = {\n",
        "    \"10.0\": \"+cu100\",\n",
        "    \"10.1\": \"+cu101\",\n",
        "    \"10.2\": \"\",\n",
        "}\n",
        "\n",
        "pytorch_version = \"1.7.1\" + (pytorch_suffix[version] if version in pytorch_suffix else \"+cu110\")\n",
        "torchvision_version = \"0.8.2\" + (pytorch_suffix[version] if version in pytorch_suffix else \"+cu110\")\n",
        "\n",
        "%cd /content\n",
        "!git clone https://github.com/galatolofederico/clip-glass.git\n",
        "%cd clip-glass\n",
        "\n",
        "try:\n",
        "  import torch\n",
        "except:\n",
        "  !pip install torch=={pytorch_version} -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "try:\n",
        "  import torchvision\n",
        "except:\n",
        "  !pip install torchvision=={torchvision_version} -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "!pip install pytorch_pretrained_biggan==0.1.1 pymoo==0.4.2.1 kornia==0.4.1 ftfy==5.8 tensorboard==2.4.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvZFRZtcv8Mp",
        "cellView": "form"
      },
      "source": [
        "#@title CLIP-GLaSS settings\n",
        "import argparse\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pickle\n",
        "from pymoo.optimize import minimize\n",
        "from pymoo.algorithms.so_genetic_algorithm import GA\n",
        "from pymoo.factory import get_algorithm, get_decision_making, get_decomposition\n",
        "from pymoo.visualization.scatter import Scatter\n",
        "import torchvision\n",
        "from IPython.display import Image, display\n",
        "import urllib.request\n",
        "\n",
        "\n",
        "from config import get_config\n",
        "from problem import GenerationProblem\n",
        "from operators import get_operators\n",
        "\n",
        "target = \"a dog in the woods\" #@param {type:\"string\"}\n",
        "config = \"DeepMindBigGAN256\" #@param [\"DeepMindBigGAN256\", \"DeepMindBigGAN512\", \"StyleGAN2_ffhq_d\", \"StyleGAN2_car_d\", \"StyleGAN2_church_d\", \"StyleGAN2_ffhq_nod\", \"StyleGAN2_car_nod\", \"StyleGAN2_church_nod\", \"GPT2\"]\n",
        "save_each = 10 #@param {type:\"number\"}\n",
        "generations = 500 #@param {type:\"number\"}\n",
        "\n",
        "if config == \"GPT2\":\n",
        "  try:\n",
        "    urllib.request.urlretrieve(target, \"./target\")\n",
        "    target = \"./target\"\n",
        "  except Exception as e:\n",
        "    print(e)\n",
        "    raise Exception(\"Target must be a vaild URL when using GPT2\")\n",
        "    \n",
        "\n",
        "if \"ffhq\" in config:\n",
        "  ! ./download-weights.sh StyleGAN2-ffhq\n",
        "if \"church\" in config:\n",
        "  ! ./download-weights.sh StyleGAN2-church\n",
        "if \"car\" in config:\n",
        "  ! ./download-weights.sh StyleGAN2-car\n",
        "if config == \"GPT2\":\n",
        "  ! ./download-weights.sh GPT2\n",
        "\n",
        "config = argparse.Namespace(\n",
        "    config=config,\n",
        "    target=target,\n",
        "    device=\"cuda\",\n",
        "    generations=generations,\n",
        "    save_each=save_each,\n",
        "    tmp_folder=\"./tmp\"\n",
        ")\n",
        "\n",
        "vars(config).update(get_config(config.config))\n",
        "\n",
        "\n",
        "iteration = 0\n",
        "def save_callback(algorithm):\n",
        "    global iteration\n",
        "    global config\n",
        "\n",
        "    iteration += 1\n",
        "    if iteration % config.save_each == 0 or iteration == config.generations:\n",
        "        if config.problem_args[\"n_obj\"] == 1:\n",
        "            sortedpop = sorted(algorithm.pop, key=lambda p: p.F)\n",
        "            X = np.stack([p.X for p in sortedpop])  \n",
        "        else:\n",
        "            X = algorithm.pop.get(\"X\")\n",
        "        \n",
        "        ls = config.latent(config)\n",
        "        ls.set_from_population(X)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            generated = algorithm.problem.generator.generate(ls, minibatch=config.batch_size)\n",
        "            name = \"genetic-it-%d.jpg\" % (iteration) if iteration < config.generations else \"genetic-it-final.jpg\"\n",
        "\n",
        "            if config.task == \"txt2img\":\n",
        "                algorithm.problem.generator.save(generated, os.path.join(config.tmp_folder, name))\n",
        "                display(Image(os.path.join(config.tmp_folder, name)))\n",
        "            elif config.task == \"img2txt\":\n",
        "                print(\"\\n\".join(generated))\n",
        "        \n",
        "\n",
        "problem = GenerationProblem(config)\n",
        "operators = get_operators(config)\n",
        "\n",
        "if not os.path.exists(config.tmp_folder): os.mkdir(config.tmp_folder)\n",
        "\n",
        "algorithm = get_algorithm(\n",
        "    config.algorithm,\n",
        "    pop_size=config.pop_size,\n",
        "    sampling=operators[\"sampling\"],\n",
        "    crossover=operators[\"crossover\"],\n",
        "    mutation=operators[\"mutation\"],\n",
        "    eliminate_duplicates=True,\n",
        "    callback=save_callback,\n",
        "    **(config.algorithm_args[config.algorithm] if \"algorithm_args\" in config and config.algorithm in config.algorithm_args else dict())\n",
        ")\n",
        "\n",
        "res = minimize(\n",
        "    problem,\n",
        "    algorithm,\n",
        "    (\"n_gen\", config.generations),\n",
        "    save_history=False,\n",
        "    verbose=True,\n",
        ")\n",
        "\n",
        "\n",
        "pickle.dump(dict(\n",
        "    X = res.X,\n",
        "    F = res.F,\n",
        "    G = res.G,\n",
        "    CV = res.CV,\n",
        "), open(os.path.join(config.tmp_folder, \"genetic_result\"), \"wb\"))\n",
        "\n",
        "\n",
        "if config.problem_args[\"n_obj\"] == 1:\n",
        "    X = np.atleast_2d(res.X)\n",
        "else:\n",
        "    try:\n",
        "        result = get_decision_making(\"pseudo-weights\", [0, 1]).do(res.F)\n",
        "    except:\n",
        "        print(\"Warning: cant use pseudo-weights\")\n",
        "        result = get_decomposition(\"asf\").do(res.F, [0, 1]).argmin()\n",
        "    X = res.X[result]\n",
        "    X = np.atleast_2d(X)\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"RESULT\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "\n",
        "ls = config.latent(config)\n",
        "ls.set_from_population(X)\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated = problem.generator.generate(ls)\n",
        "\n",
        "if config.task == \"txt2img\":\n",
        "    problem.generator.save(generated, os.path.join(config.tmp_folder, \"output.jpg\"))\n",
        "    display(Image(os.path.join(config.tmp_folder, \"output.jpg\")))\n",
        "elif config.task == \"img2txt\":\n",
        "    print(generated)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}